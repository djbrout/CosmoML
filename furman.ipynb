{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "For the final project, your task is to predict the type of galaxies based on a number of measurements and calculations about the images of the galaxies.  This is similar to the [Galaxy Zoo](http://zoo1.galaxyzoo.org/) project we discussed in class, but rather than starting from the images themselves, we are starting with some properties of the galaxies measured from the images.\n",
    "\n",
    "The data are fully described in [Fischer et al (2019)](https://arxiv.org/abs/1811.02580), a recent paper by several U. Penn researchers, including Helena Dominguez-Sanchez, whom you met in class on April 17.\n",
    "Don't worry.  You don't need to read that paper to do this project.  Helena explained the important aspects of the data in class.  (Her slides are available on [canvas](https://canvas.upenn.edu/files/76244434/).)  But if you feel inspired to read more about it, please do take a look at the paper.\n",
    "\n",
    "The Fischer et al paper describes quite a lot of measurements based on different kinds of fits to the images.  We have extracted a subset of the measurements into a smaller catalog, which should be easier for you to work with.  Specifically, we selected columns related to the bulge + disk decomposition of the galaxy (called SE for Sersic + Exponential in the paper).\n",
    "\n",
    "The columns in this catalog are:\n",
    "\n",
    "* id = A numeric ID identifying the galaxy\n",
    "* gal_type = Which type of galaxy this is.  We discuss this more below.\n",
    "* ra = Right Ascension in degrees.  Kind of like longitude on the sky.\n",
    "* dec = Declination in degrees.  Like latitude on the sky.\n",
    "* redshift = A measure of how far away the galaxy is.\n",
    "* log_luminosity = Base 10 logarithm of the galaxy's brightness (aka luminosity) measured as a multiple of the sun's luminosity.\n",
    "* color = Lr / Lg, the ratio of the luminosity at red wavelengths to the luminosity at green wavelengths.\n",
    "* radius = The half-light radius of the galaxy (called Re in Helena's slides) according to the bulge + disk fit in kiloparsecs (kpc; see below for definition of kpc).\n",
    "* b_over_a = The ratio of the semi-minor axis of the galaxy (b) to the semi-major axis (a).  b_over_a = 1 is a circle. b_over_a close to 0 is a very elongated ellipse.\n",
    "* pos_angle = The position angle of the semi-minor axis of the galaxy on the sky in degrees.\n",
    "* bulge_fract = The fraction of the total light that was found to be in the bulge component (called B/T in Helena's slides).\n",
    "* sersic_n = The Sersic index of the bulge component of the fit.\n",
    "* r_bulge = The half-light radius of the bulge component of the fit in kiloparsecs (kpc).\n",
    "* r_disk = The half-light radius of the disk component of the fit in kiloparsecs (kpc).\n",
    "\n",
    "Radii are given in kpc above, a common distance unit used by astronomers. For reference, 1 kpc = 1000 pc, and 1 pc = 3.26 light years.\n",
    "\n",
    "--- \n",
    "\n",
    "The gal_type column is your target (y).  The others you may use as your predictors (x_i).\n",
    "\n",
    "For the galaxy type, we distilled the morphological classification described in Fischer et al into 4 broad categories.\n",
    "\n",
    "* gal_type = 1 are elliptical galaxies.  In the paper, these are called E.  They have TTYPE <= 0 and P_S0 <= 0.5.\n",
    "* gal_type = 2 are lenticular galaxies.  In the paper, these are called S0.  They have TTYPE <= 0 and P_S0 > 0.5.\n",
    "* gal_type = 3 are tight spiral galaxies.  In the paper, these are described as 0 < TType < 3.  We will call them S1.\n",
    "* gal_type = 4 are loose spiral galaxies.  In the paper, these are described as TType > 3.  We will call them S2.\n",
    "\n",
    "Note: in addition to the catalog described above, we are also providing the complete catalog described in Fischer et al for g and r bands.  You are not required to use it, but you may do so if you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "For the first stage of the project, we'll start with the easier task of just distinguishing the two most extreme galaxy types: 1 vs 4, or E vs S2.\n",
    "\n",
    "You may use any of the various characterization methods we have used throughout the course to do the prediction.  (Or even ones we haven't covered if you feel so inclined.)  You should write two functions:\n",
    "\n",
    "* train_galaxy_predictions takes as input a set of training data and returns some results, which can be used to make predictions.\n",
    "* validate_galaxy_predictions takes the results from the first function and some validation data to predict the galaxy types.  It should return n array of predicted galaxy types.\n",
    "\n",
    "You can decide how you want to split the provided data into training and validation samples.  (When you submit your project, we will run your code using the full given data as the training set.  We have reserved a validation sample of approximately equal size to use for the validation step.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_galaxy_predictions_1(gal_type, data, data_g, data_r):\n",
    "    \"\"\"\n",
    "    Use sklearn's AdaBoostClassifier function to fit galaxy data.\n",
    "    \n",
    "    Returns the trained model.\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    \n",
    "    # Take all columns of data array except the first two which are ID and gal_type\n",
    "    X = np.array(data.tolist())[:, 2:]\n",
    "    Y = gal_type\n",
    "    \n",
    "    model = AdaBoostClassifier(n_estimators=100, learning_rate=0.1)\n",
    "    model = model.fit(X, Y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def validate_galaxy_predictions_1(result, data, data_g, data_r):\n",
    "    \"\"\"\n",
    "    Uses result, a model trained using sklearn's AdaBoostClassifier, and makes predictions.\n",
    "    \n",
    "    Returns predictions in an array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Take all columns of data array except the first two which are ID and gal_type\n",
    "    X = np.array(data.tolist())[:, 2:]\n",
    "    return result.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num correct =  297\n",
      "Num total =  300\n",
      "Fraction correct =  0.99\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "gal_file_name = 'training_galaxies.dat'\n",
    "full_g_file_name = 'training_galaxies_full_g.dat'\n",
    "full_r_file_name = 'training_galaxies_full_r.dat'\n",
    "\n",
    "gal_data = np.genfromtxt(gal_file_name, names=True, dtype=None)\n",
    "full_g_data = np.genfromtxt(full_g_file_name, names=True, dtype=None)\n",
    "full_r_data = np.genfromtxt(full_r_file_name, names=True, dtype=None)\n",
    "\n",
    "# For now, limit the data to those galaxies with gal_type == 1 or 4\n",
    "gal_type = gal_data['gal_type'].copy()\n",
    "type_1_4 = (gal_type == 1) | (gal_type == 4)\n",
    "gal_data = gal_data[type_1_4]\n",
    "full_g_data = full_g_data[type_1_4]\n",
    "full_r_data = full_r_data[type_1_4]\n",
    "gal_type = gal_type[type_1_4]\n",
    "\n",
    "# Zero out the gal_type column in the input data, so it can't be used to cheat.  :)\n",
    "gal_data['gal_type'][:] = 0\n",
    "\n",
    "# Split up the input into a training and validation set as you want.\n",
    "# When we run this, we will use the full data arrays as input, and some different (not provided!) data as validation.\n",
    "###\n",
    "training_frac = 0.75\n",
    "nExamples = gal_type.shape[0]\n",
    "nTrain = int(training_frac * nExamples)\n",
    "\n",
    "training_data = gal_data[:nTrain]\n",
    "training_data_g = full_g_data[:nTrain]\n",
    "training_data_r = full_r_data[:nTrain]\n",
    "training_gal_type = gal_type[:nTrain]\n",
    "validation_data = gal_data[nTrain:]\n",
    "validation_data_g = full_g_data[nTrain:]\n",
    "validation_data_r = full_r_data[nTrain:]\n",
    "validation_gal_type = gal_type[nTrain:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "training_data, validation_data, training_gal_type, validation_gal_type = train_test_split(\n",
    "    gal_data,\n",
    "    gal_type,\n",
    "    test_size=1-training_frac,\n",
    "    random_state=2019)\n",
    "\n",
    "# Your function can ignore training_data_g and training_data_r if you don't want to use them.\n",
    "# But the function signature needs to take 4 values, since we will pass them to your function when we run this.\n",
    "result = train_galaxy_predictions_1(training_gal_type, training_data, training_data_g, training_data_r)\n",
    "\n",
    "predicted_gal_type = validate_galaxy_predictions_1(result, validation_data, validation_data_g, validation_data_r)\n",
    "\n",
    "print('Num correct = ',np.sum(predicted_gal_type == validation_gal_type))\n",
    "print('Num total = ',len(validation_gal_type))\n",
    "print('Fraction correct = ',np.sum(predicted_gal_type == validation_gal_type) / len(validation_gal_type))\n",
    "# Note: It may be helpful to construct a confusion matrix to better quantify how well you are doing here, rather\n",
    "# than just looking at the overal fraction correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "The second stage of the project is the same, except we will try to classify the spirals into their two sub-categories, S1 vs S2 (i.e. types 3 vs 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_galaxy_predictions_2(gal_type, data, data_g, data_r):\n",
    "    \"\"\"\n",
    "    Use sklearn's AdaBoostClassifier function to fit galaxy data.\n",
    "    \n",
    "    Returns the trained model.\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "    \n",
    "    # Take all columns of data array except the first two which are ID and gal_type\n",
    "    X = np.array(data.tolist())[:, 2:]\n",
    "    Y = gal_type\n",
    "    \n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    model = model.fit(X, Y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def validate_galaxy_predictions_2(result, data, data_g, data_r):\n",
    "    \"\"\"\n",
    "    Uses result, a model trained using sklearn's AdaBoostClassifier, and makes predictions.\n",
    "    \n",
    "    Returns predictions in an array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Take all columns of data array except the first two which are ID and gal_type\n",
    "    X = np.array(data.tolist())[:, 2:]\n",
    "    return result.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num correct =  239\n",
      "Num total =  295\n",
      "Fraction correct =  0.8101694915254237\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "gal_file_name = 'training_galaxies.dat'\n",
    "full_g_file_name = 'training_galaxies_full_g.dat'\n",
    "full_r_file_name = 'training_galaxies_full_r.dat'\n",
    "\n",
    "gal_data = np.genfromtxt(gal_file_name, names=True, dtype=None)\n",
    "full_g_data = np.genfromtxt(full_g_file_name, names=True, dtype=None)\n",
    "full_r_data = np.genfromtxt(full_r_file_name, names=True, dtype=None)\n",
    "\n",
    "# This time, limit the data to those galaxies with gal_type == 3 or 4\n",
    "gal_type = gal_data['gal_type'].copy()\n",
    "type_3_4 = (gal_type == 3) | (gal_type == 4)\n",
    "gal_data = gal_data[type_3_4]\n",
    "full_g_data = full_g_data[type_3_4]\n",
    "full_r_data = full_r_data[type_3_4]\n",
    "gal_type = gal_type[type_3_4]\n",
    "\n",
    "# Zero out the gal_type column in the input data, so it can't be used to cheat.  :)\n",
    "gal_data['gal_type'][:] = 0\n",
    "\n",
    "# Split up the input into a training and validation set as you want.\n",
    "# When we run this, we will use the full data arrays as input, and some different (not provided!) data as validation.\n",
    "###\n",
    "training_frac = 0.75\n",
    "nExamples = gal_type.shape[0]\n",
    "nTrain = int(training_frac * nExamples)\n",
    "###\n",
    "\n",
    "training_data = gal_data[:nTrain]\n",
    "training_data_g = full_g_data[:nTrain]\n",
    "training_data_r = full_r_data[:nTrain]\n",
    "training_gal_type = gal_type[:nTrain]\n",
    "validation_data = gal_data[nTrain:]\n",
    "validation_data_g = full_g_data[nTrain:]\n",
    "validation_data_r = full_r_data[nTrain:]\n",
    "validation_gal_type = gal_type[nTrain:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "training_data, validation_data, training_gal_type, validation_gal_type = train_test_split(\n",
    "    gal_data,\n",
    "    gal_type,\n",
    "    test_size=1-training_frac,\n",
    "    random_state=2019)\n",
    "\n",
    "# Your function can ignore training_data_g and training_data_r if you don't want to use them.\n",
    "# But the function signature needs to take 4 values, since we will pass them to your function when we run this.\n",
    "result = train_galaxy_predictions_2(training_gal_type, training_data, training_data_g, training_data_r)\n",
    "\n",
    "predicted_gal_type = validate_galaxy_predictions_2(result, validation_data, validation_data_g, validation_data_r)\n",
    "\n",
    "print('Num correct = ',np.sum(predicted_gal_type == validation_gal_type))\n",
    "print('Num total = ',len(validation_gal_type))\n",
    "print('Fraction correct = ',np.sum(predicted_gal_type == validation_gal_type) / len(validation_gal_type))\n",
    "# Note: It may be helpful to construct a confusion matrix to better quantify how well you are doing here, rather\n",
    "# than just looking at the overal fraction correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "Finally, in the third stage, we will try to classify all 4 types.\n",
    "\n",
    "You may find it simpler to do this in two steps.  First separate E and S0 galaxies (aka, types 1 and 2) from spiral galaxies (S1 and S2, aka types 3 and 4).  Then within these two groups classify E vs S0 and S1 vs S2.  This would allow you to use classifiers that are best done on binary classification.  \n",
    "\n",
    "Or you may want to try to use a classifier that can handle more than 2 types for the target and do the whole process at once.  Or you may find that some other combination of methods is appropriate.\n",
    "\n",
    "It should be noted that we don't expect you to be able to do a great job separating the E and S0 galaxies from each other.  So don't feel too bad if you aren't getting great results on that part of the classification.  However, we think you should be able to do a decent job separating the other types from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num correct =  545\n",
      "Num total =  723\n",
      "Fraction correct =  0.7538035961272476\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_galaxy_predictions_3(gal_type, data, data_g, data_r):\n",
    "    \"\"\"\n",
    "    Use sklearn's AdaBoostClassifier function to fit galaxy data.\n",
    "    \n",
    "    Returns the trained model.\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    # Train model to separate galaxy types EII and S0 from S1 and S2\n",
    "    X = np.array(data.tolist())[:, 2:]\n",
    "    Y = gal_type.copy()\n",
    "    Y[Y == 1], Y[Y == 2], Y[Y == 3], Y[Y == 4] = 0, 0, 1, 1\n",
    "    model_EII_S0_vs_S1_S2 = AdaBoostClassifier(n_estimators=100, learning_rate=0.1)\n",
    "    model_EII_S0_vs_S1_S2 = model_EII_S0_vs_S1_S2.fit(X, Y)\n",
    "    \n",
    "    # Train model to separate galaxy types EII from S0\n",
    "    X = np.array(data.tolist())[:, 2:]\n",
    "    Y = gal_type.copy()\n",
    "    sersic = (gal_type == 1) | (gal_type == 2)\n",
    "    X = X[sersic, :]\n",
    "    Y = Y[sersic]\n",
    "    Y[Y == 1], Y[Y == 2] = 0, 1\n",
    "    model_EII_vs_S0 = SVC(kernel='linear')\n",
    "    model_EII_vs_S0 = model_EII_vs_S0.fit(X, Y)\n",
    "    \n",
    "    # Train model to separate galaxy types S1 from S2\n",
    "    X = np.array(data.tolist())[:, 2:]\n",
    "    Y = gal_type.copy()\n",
    "    sersic = (gal_type == 3) | (gal_type == 4)\n",
    "    Y[Y == 3], Y[Y == 4] = 0, 1\n",
    "    X = X[sersic, :]\n",
    "    Y = Y[sersic]\n",
    "    \n",
    "    model_S1_vs_S2 = LinearDiscriminantAnalysis()\n",
    "    model_S1_vs_S2 = model_S1_vs_S2.fit(X, Y)\n",
    "    \n",
    "    return model_EII_S0_vs_S1_S2, model_EII_vs_S0, model_S1_vs_S2\n",
    "\n",
    "def validate_galaxy_predictions_3(result, data, data_g, data_r):\n",
    "    \"\"\"\n",
    "    Uses result, a model trained using sklearn's AdaBoostClassifier, and makes predictions.\n",
    "    \n",
    "    Returns predictions in an array.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = np.array(data.tolist())[:, 2:]\n",
    "    \n",
    "    model_EII_S0_vs_S1_S2, model_EII_vs_S0, model_S1_vs_S2 = result\n",
    "    \n",
    "    EII_S0 = model_EII_S0_vs_S1_S2.predict(X) == 0\n",
    "    S1_S2 = model_EII_S0_vs_S1_S2.predict(X) == 1\n",
    "    \n",
    "    X_EII_S0 = X[EII_S0, :]\n",
    "    X_S1_S2 =  X[S1_S2, :]\n",
    "    \n",
    "    Y_EII_S0 = model_EII_vs_S0.predict(X_EII_S0) + 1\n",
    "    Y_S1_S2 = model_S1_vs_S2.predict(X_S1_S2) + 3\n",
    "    \n",
    "    Y_pred = np.zeros(X.shape[0])\n",
    "    Y_pred[EII_S0] = Y_EII_S0\n",
    "    Y_pred[S1_S2] = Y_S1_S2\n",
    "    \n",
    "    return Y_pred.astype(int)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "gal_file_name = 'training_galaxies.dat'\n",
    "full_g_file_name = 'training_galaxies_full_g.dat'\n",
    "full_r_file_name = 'training_galaxies_full_r.dat'\n",
    "\n",
    "gal_data = np.genfromtxt(gal_file_name, names=True, dtype=None)\n",
    "full_g_data = np.genfromtxt(full_g_file_name, names=True, dtype=None)\n",
    "full_r_data = np.genfromtxt(full_r_file_name, names=True, dtype=None)\n",
    "\n",
    "# Zero out the gal_type column in the input data, so it can't be used to cheat.  :)\n",
    "gal_type = gal_data['gal_type'].copy()\n",
    "gal_data['gal_type'][:] = 0\n",
    "\n",
    "# Split up the input into a training and validation set as you want.\n",
    "# When we run this, we will use the full data arrays as input, and some different (not provided!) data as validation.\n",
    "###\n",
    "training_frac = 0.65\n",
    "nExamples = gal_type.shape[0]\n",
    "nTrain = int(training_frac * nExamples)\n",
    "###\n",
    "\n",
    "training_data = gal_data[:nTrain]\n",
    "training_data_g = full_g_data[:nTrain]\n",
    "training_data_r = full_r_data[:nTrain]\n",
    "training_gal_type = gal_type[:nTrain]\n",
    "validation_data = gal_data[nTrain:]\n",
    "validation_data_g = full_g_data[nTrain:]\n",
    "validation_data_r = full_r_data[nTrain:]\n",
    "validation_gal_type = gal_type[nTrain:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "training_data, validation_data, training_gal_type, validation_gal_type = train_test_split(\n",
    "    gal_data,\n",
    "    gal_type,\n",
    "    test_size=1-training_frac,\n",
    "    random_state=2019)\n",
    "\n",
    "# Your function can ignore training_data_g and training_data_r if you don't want to use them.\n",
    "# But the function signature needs to take 4 values, since we will pass them to your function when we run this.\n",
    "result = train_galaxy_predictions_3(training_gal_type, training_data, training_data_g, training_data_r)\n",
    "\n",
    "predicted_gal_type = validate_galaxy_predictions_3(result, validation_data, validation_data_g, validation_data_r)\n",
    "\n",
    "print('Num correct = ',np.sum(predicted_gal_type == validation_gal_type))\n",
    "print('Num total = ',len(validation_gal_type))\n",
    "print('Fraction correct = ',np.sum(predicted_gal_type == validation_gal_type) / len(validation_gal_type))\n",
    "# Note: It may be helpful to construct a (4x4) confusion matrix to better quantify how well you are doing here, rather\n",
    "# than just looking at the overal fraction correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
